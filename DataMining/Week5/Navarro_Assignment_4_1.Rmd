---
title: "Navarro_Assignment_4_1"
author: "John Navarro"
date: "February 4, 2017"
output: pdf_document
---
# 1. Generate training and holdout samples 

```{r}

germanCredit<- read.csv("C:/Users/JohntheGreat/Documents/MSCA/DataMining/Week1/german_credit.csv", header=TRUE, sep=",")
# Need to split the data into Train and Holdout portions
set.seed(12345)
train_ind <- sample(seq_len(nrow(germanCredit)), size = 700)
# Randomly separate into two data frames: Train and Holdout
Train <- germanCredit[train_ind, ]
Holdout<- germanCredit[-train_ind, ]
```

# 2. Build a Logistic Regression model for Train

```{r}
full <- glm(formula = Creditability~., data=Train, family = binomial(link=logit))
summary(full)
#round(log.model$coefficients,3)
```


# 3. Choose only the main-effects

```{r}


# null model class
null <- glm(formula = Creditability~1, data=Train, family = binomial(link=logit))
summary(null)
drop1(full)

```

 
```{r}
log.model.min.AIC <- glm(formula = Creditability~ Account.Balance+Payment.Status.of.Previous.Credit+Value.Savings.Stocks+Instalment.per.cent+Duration.of.Credit..month.+Sex...Marital.Status+Guarantors+Most.valuable.available.asset+Type.of.apartment, data=Train, family = binomial(link=logit))
summary(log.model.min.AIC)
```
I built a glm model starting with the predictors with the highest values in the AIC column from the drop1()function. By eliminating the following 11 variables (Purpose, Duration.in.Current.address, Age..years., Occupation, No.of.dependents, No.of.Credits.at.this.Bank, Telephone, Foreign.Worker, Concurrent.Credits, Length.of.current.employment, Credit.Amount), we are able to minimize AIC (714.03), which is lower than the AIC achieved by the full model (724.73) and of course lower than the null model (860.57)

# 4. Generate the confusion matrix on Train data
```{r}
xp=log.model.min.AIC$fitted.values
xp[xp>=0.5]=1
xp[xp<0.5]=0
table(Train$Creditability, xp)
round(prop.table(table(Train$Creditability, xp),1),2)
table(Train[,1], xp)
```
*Do you like the model Why or why not?*
This model does a good job of predicting good creditors. It is successful predicting good credit 90% of the time, and is incorrect 10 % of the time. When it predicts that a creditor is bad, it is only correct 44% of the time. While 56% of the time its prediction that the creditor is bad is incorrect. This is not as bad as if it was the opposite way (doing a poor job of predicting good credit). This model can be improved in its prediction of poor credit. But at least it is over predicting bad credit and not underpredicting bad credit.

# 5. Perform Holdout validation testing
```{r}
# Holdout validation
# returns probability that y =1 given x
predicted.values = predict(log.model.min.AIC, newdata = Holdout, type = "response")
class(predicted.values)
predicted.values[predicted.values>=0.5] = 1
predicted.values[predicted.values<0.5] = 0
table(Holdout[,1], predicted.values)
#predicted.values
# Confusion matrix for holdout sample
round(prop.table(table(Holdout[,1],predicted.values),1),2)

```

*Do you like the model Why or why not?*

This model shows similar results in the holdout set. Which gives us confidence that the model is stable. And more confidence in its results. I like this model since it has a high success rate of predicting good credit. Despite being inaccurate with the poor credit predictions, at least it over predicts bad credit instead of underpredicting bad credit.