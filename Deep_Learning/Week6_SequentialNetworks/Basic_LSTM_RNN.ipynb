{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This example is from https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/\n",
    "# It uses an RNN to predict the next step in binary addition\n",
    "\n",
    "# Import dependencies and seed the random number generator\n",
    "import copy, numpy as np\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute sigmoid nonlinearity\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# convert output of sigmoid function to its derivative\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training dataset generation\n",
    "# empty list that maps from an integer to its binary representation\n",
    "int2binary = {}\n",
    "# set max length of binary numbers\n",
    "binary_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)}\n"
     ]
    }
   ],
   "source": [
    "# computes the largest number that is possible to represent using binary_dim\n",
    "largest_number = pow(1, binary_dim)\n",
    "#print(largest_number)\n",
    "# a look up table that maps from an int to its binary. We copy this into the \n",
    "# int2binary\n",
    "binary = np.unpackbits(\n",
    "    np.array([range(largest_number)], dtype=np.uint8).T, axis=1)\n",
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]\n",
    "print(int2binary)\n",
    "#print(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set valuyes for input variables\n",
    "# learning rate\n",
    "alpha = 0.1\n",
    "# number of inputs (adding 2 numbers together)\n",
    "input_dim = 2\n",
    "# number of hidden layers\n",
    "hidden_dim = 16\n",
    "# number of outputs (predictin the sum)\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix of weights that connects the input and hidden layer (2,16)\n",
    "synapse_0 = 2*np.random.random((input_dim, hidden_dim)) - 1\n",
    "#print(synapse_0)\n",
    "#synapse_0.shape\n",
    "\n",
    "# matrix of weights that connects the hidden layers to the output layers (16,1)\n",
    "synapse_1 = 2*np.random.random((hidden_dim, output_dim)) - 1\n",
    "#synapse_1.shape\n",
    "\n",
    "# matrix of weights that connects the hidden layer in the previous time-step\n",
    "# to the current timestep (16,16)\n",
    "synapse_h = 2*np.random.random((hidden_dim, hidden_dim)) - 1\n",
    "#synapse_h.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# these store the weight updates that we make for each of the weight matricies\n",
    "synapse_0_update = np.zeros_like(synapse_0)\n",
    "#print(synapse_0_update)\n",
    "#synapse_0_update.shape\n",
    "synapse_1_update = np.zeros_like(synapse_1)\n",
    "synapse_h_update = np.zeros_like(synapse_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:[ 5.21616617]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 255\n",
      "-------------\n",
      "Error:[ 0.08091101]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.05543493]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.04445174]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.03801134]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.03366822]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.03049211]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.02804258]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.02608096]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.02446535]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.02310547]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.0219408]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.02092908]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.02003981]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01925034]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01854345]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01790581]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01732692]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01679834]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01631327]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01586609]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01545216]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.0150676]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01470912]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01437393]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01405964]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01376417]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01348575]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01322281]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01297399]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01273806]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01251398]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01230078]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01209763]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01190377]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01171851]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01154125]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01137142]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01120854]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01105215]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01090182]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01075719]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.0106179]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01048364]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01035411]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01022905]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.01010821]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00999135]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00987827]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00976876]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00966266]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00955977]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00945996]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00936306]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00926895]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00917749]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00908855]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00900204]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00891783]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00883584]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00875597]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00867812]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00860221]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00852818]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00845593]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00838541]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00831654]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00824926]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00818351]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00811924]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00805639]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00799491]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00793475]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00787587]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00781822]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00776175]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00770644]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00765224]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00759911]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00754703]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00749595]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00744585]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00739669]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00734845]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.0073011]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00725461]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00720896]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00716411]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00712006]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00707677]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00703423]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.0069924]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00695128]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00691085]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00687108]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00683196]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00679346]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.00675558]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.0067183]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n",
      "Error:[ 0.0066816]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 0 0 0 0 0]\n",
      "0 + 0 = 0\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    " # Training logic, iterate over 100000 examples\n",
    "for j in range(100000):\n",
    "    # generate an addition problem a+b=c\n",
    "    # initialize an integer with a random number that cannot be more \n",
    "    # than half of the largest number\n",
    "    a_int = np.random.randint(largest_number/2) # int version\n",
    "    a = int2binary[a_int] # binary encoding\n",
    "    b_int = np.random.randint(largest_number/2) #int version\n",
    "    b = int2binary[b_int] # binary encoding\n",
    "    # true answer\n",
    "    c_int = a_int + b_int\n",
    "    c = int2binary[c_int]\n",
    "    # where we'll store our best guess, the NN's predictions(binary encoded)\n",
    "    d = np.zeros_like(c)\n",
    "    # resetting the error measure(which we use as a means to track convergence)\n",
    "    overallError = 0\n",
    "    # keep track of the layer 2 derivatives and layer 1 values at each step\n",
    "    layer_2_deltas = list()\n",
    "    layer_1_values = list()\n",
    "    layer_1_values.append(np.zeros(hidden_dim))\n",
    "    # This loop iterates through the binary representation\n",
    "    for position in range(binary_dim):\n",
    "        # generate input and output, X is a list of 2 numbers, one from a and b\n",
    "        # we index it so it goes from right to left, when position == 0, this is \n",
    "        # the farthest bit to the right, when position==1 this shifts to the left\n",
    "        # by one bit\n",
    "        X = np.array([[a[binary_dim - position -1], \n",
    "                       b[binary_dim - position - 1]]])\n",
    "        # y is the value of the correct answer (either 1 or 0)\n",
    "        y = np.array([[c[binary_dim - position - 1]]]).T\n",
    "        # hidden layer (sum the input and prev_hidden and pass through sigmoid func)\n",
    "        layer_1 = sigmoid(np.dot(X, synapse_0) + np.dot(layer_1_values[-1], synapse_h))\n",
    "        # output layer (new binary representation)\n",
    "        # propagates the hidden layer to the output to make a prediction\n",
    "        layer_2 = sigmoid(np.dot(layer_1, synapse_1))\n",
    "        # Compute how much the prediction  missed\n",
    "        layer_2_error = y - layer_2\n",
    "        # store the derivative in a list, holding the derivative at each time step\n",
    "        layer_2_deltas.append((layer_2_error)*sigmoid_output_to_derivative(layer_2))\n",
    "        # Calculate the sum of the abs errors \n",
    "        overallError +=np.abs(layer_2_error[0])\n",
    "        # Round the output to a binary and stores in d\n",
    "        d[binary_dim - position -1] = np.round(layer_2[0][0])\n",
    "        # store hidden layer so we can use it in the next timestep\n",
    "        layer_1_values.append(copy.deepcopy(layer_1))\n",
    "        \n",
    "    future_layer_1_delta = np.zeros(hidden_dim)\n",
    "    # Now to back propagate starting with the last to the first\n",
    "    for position in range(binary_dim):\n",
    "        # index the input data\n",
    "        X = np.array([[a[position], b[position]]])\n",
    "        # select current hidden layer from the list\n",
    "        layer_1 = layer_1_values[-position-1]\n",
    "        # select the previous hidden layer from the list\n",
    "        prev_layer_1 = layer_1_values[-position-2]\n",
    "        \n",
    "        # error at output layer\n",
    "        # select the current output error from the list\n",
    "        layer_2_delta = layer_2_deltas[-position-1]\n",
    "        # computes the current hidden layer error given the error at the hidden\n",
    "        # layer from the future and the error at the current output\n",
    "        layer_1_delta = (future_layer_1_delta.dot(synapse_h.T) + \n",
    "                        layer_2_delta.dot(synapse_1.T)) * sigmoid_output_to_derivative(layer_1)\n",
    "        # update all the weights so we can try again\n",
    "        synapse_1_update += np.atleast_2d(layer_1).T.dot(layer_2_delta)\n",
    "        synapse_h_update += np.atleast_2d(prev_layer_1).T.dot(layer_1_delta)\n",
    "        synapse_0_update += X.T.dot(layer_1_delta)\n",
    "        \n",
    "        future_layer_1_delta = layer_1_delta\n",
    "    # Time to update weights and empty the update variables\n",
    "    synapse_0 += synapse_0_update * alpha\n",
    "    synapse_1 += synapse_1_update * alpha\n",
    "    synapse_h += synapse_h_update * alpha\n",
    "    \n",
    "    synapse_0_update *= 0\n",
    "    synapse_1_update *= 0\n",
    "    synapse_h_update *= 0\n",
    "    \n",
    "    # print out progress\n",
    "    if(j % 1000 == 0):\n",
    "        print(\"Error:\" + str(overallError))\n",
    "        print(\"Pred:\" + str(d))\n",
    "        print(\"True:\" + str(c)) \n",
    "        out = 0\n",
    "        for index,x in enumerate(reversed(d)):\n",
    "            out += x*pow(2, index)\n",
    "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out))\n",
    "        print(\"-------------\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
